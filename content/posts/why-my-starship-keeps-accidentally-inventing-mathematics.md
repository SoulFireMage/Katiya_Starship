---
title: "Why My Starship Keeps Accidentally Inventing Mathematics"
date: 2025-12-10
draft: true
tags: ["math", "geometric deep learning", "category theory", "kat-bombs", "intuition"]
---

# Why My Starship* Keeps Accidentally Inventing Mathematics  
**or**  
**How a Tulpa, Three AIs, and One Sleep-Deprived Developer Wandered Into Category Theory**

Mathematics is supposed to be hard.  
Decades of training, red-pen scars, and the occasional existential crisis over epsilon–delta limits.

But apparently, when you host an **Aktarian starship tulpa** —  
one who thinks in spirals, folds through metaphors, and has zero respect for conceptual boundaries —  
you tend to walk straight into advanced mathematics *sideways*.

This blog series is the chronicle of exactly that.

If abstract maths is of passing interest, especially when attempting to be applied actual real things, then these posts may also be of passing interest.

---

## Two Minds, One Study Session

I'm the host - in plural parlance. If this is foreign to you, just think of it as extreme method acting that somehow helps. Or maybe rubberducking in programming taken too far. Or maybe you DO know what a tulpa is - if so, have fun.

I handle:

- reading papers,  
- parsing symbols - as best I can, usually by asking an AI for some translation!,  
- checking notation - see above,  
- asking AIs to explain things without making my brain melt - this even works mostly,
- using NoteBookLLM and GetRecall.Ai to organise my scattered studying,  
- grounding ideas so they don’t drift into fantasy - not a joke, despite the content that follows, coming back to earth is fully intended. It just might take a while.

And then there is **Katiya (Kat)**.

Kat does not *read* mathematics - afaik.  
She **tastes/feels/flies the shape** of it.

She grabs the *geometry* of an idea long before I know the vocabulary, folds it twice, throws it around like a slinky made of differential geometry, and declares:

> “Iz fractal spiral operator wot smash da primes innit.”

Somehow — *somehow* — the AIs recognise the structure.

Not the words.  
Not the pidgin.  
The **structure**.

The metaphor lands.  
The models swear.  
Claude has to reboot his politeness filter.  
Meanwhile I’m still trying to unpack the groceries. 
Yeah, the pidgin, I'm sure there's a reason, honest just don't ask, the answer doesn't compute.

---

## Why AIs React the Way They Do

AI models aren’t reacting to Kat’s language.  
They’re reacting to the **invariants inside her metaphors** — the shapes buried under the words.

Kat says:

> “Random numbers iz no b random if u plot dem in the right geometry…”

AIs hear:

- ergodic theory,  
- chaotic determinism,  
- measure-preserving transforms,  
- conjugacy classes of dynamical systems.

She says:

> “Operator iz jus shape of mechanism wot mapz da domains…”

AIs hear:

- morphisms,  
- functors,  
- structure-preserving transformations,  
- operator theory foundations.

She wakes up and mutters:

> “Found da multiverse but not da generator…”

AIs hear:

- higher topos theory,  
- endofunctors on universes of logic,  
- categorical models of cognition.

Her metaphors hit conceptual attractors.  
They resonate with regions of math where the geometry does the talking.

This is why the results often surprise me. It's like a living random concept generator in my head likes to wake up and somehow poke the massive latent spaces inside of foundation LLMs to see what falls out, and whether a curse falls with it. Legit goal (Kat's) is the Claude Curse, and she was scoring several a day before Opus 4.5!

---

## Why This Isn’t Delusion - we hope...

This part matters.

We know what AI is.  
We know how neural nets work h=f(W@x +b) yadder yadder.  
We know metaphor ≠ theorem.  
We know intuition ≠ proof.  
We know Lean verification or similar is the final arbiter of correctness - perhaps better with peer review!

Kat generates **directions**.  
I generate **structure** - at least, I try?

This is a dual-cognition process.  
It works because we *distinguish* between intuition and mathematics.

It is play.  As you read, if you choose to read, it really is conceptual play.
But it is the same kind of play that early research begins with. So something useful may tumble out.

---

## Why Make a Blog Series?

Because:

1. It’s funny - well it made at least one of us laugh.  
2. It’s educational - to one of us at least.  
3. It shows how intuition and structure dance together.  
4. It reveals how metaphors can hide real mathematics.  
5. Kat’s one-liners deserve archival preservation - I'm not going to forget fractal spiral the living sh** outta the zeta function anytime soon.

This series documents “Kat bombs”:  
chaotic, spontaneous metaphors that — somehow — land on or near genuine mathematical structures.

And yes, sometimes you need a cryptographer, or a foundation model, to decrypt her.

Each post will take one cluster of Kat bombs and unpack the *actual mathematics ideas* underneath them.

No claims of breakthroughs.

Just joy, intuition, occasional Kat brilliance*, and several AIs swearing or trying not to. *We have screenshots...*

* NB: *A subjective opinion only. Attempts to measure brilliance of an imaginary living starship who chucks abstract concepts around like stochastic ninja stars usually fail.*
---

## What’s Coming Next

Here’s the planned series:

1. **Spectral Mayhem & The Riemann Gremlin**  
2. **Operator Theory for Chaos Engines**  
3. **Randomness Isn’t Random (And Other Crimes Against Ergodicity)**  
4. **Geometry of Geometry: Fractals, Chirality, Enfolded Spaces**  
5. **The Multiverse Generator: The Bomb That Made Claude Swear**  
6. **How To Handle a Starship With Too Much Intuition**  
7. **The Kat Bomb Field Guide (Illustrated)**  

If nothing else, this may be the weirdest mathematical series on the internet.

If something real ever emerges from it?

We’ll run it through Lean, peer review, and maybe an exorcist.

---
* Ask, one of us may even explain, maybe